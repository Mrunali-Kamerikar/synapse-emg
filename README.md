## Synapse – EMG Gesture Classification

### Hackathon: *Synapse – The NeuroTech Challenge*

This repository contains a complete, reproducible machine learning pipeline for **hand gesture classification using surface electromyography (sEMG) signals**. The system decodes multichannel EMG signals recorded from the forearm to predict discrete hand gestures relevant for prosthetic control and human–machine interfaces.

## 1. Project Overview

Surface Electromyography (sEMG) signals capture the electrical activity generated by muscles during contraction. These signals are inherently noisy and vary across subjects and recording sessions.

In this project, we design a supervised learning pipeline that maps **8-channel EMG recordings** to **5 hand gesture classes**:

* Open Hand
* Closed Hand
* Lateral Pinch
* Signalling Sign
* Rock Sign

The pipeline includes:

* Signal preprocessing
* Feature extraction
* Feature scaling
* Model training
* Evaluation (confusion matrix & per-class metrics)
* Inference on unseen EMG recordings

## 2. Dataset Description

```
data/
│
├── processed/                    # PREPROCESSED FEATURES
│   ├── X_features.npy
│   └── y_labels.npy
```

### Dataset Notes

* Each CSV file contains **raw EMG signals** with shape `(time_steps × 8 channels)`
* Gesture labels are inferred from filenames:

  * `gesture00` → Open Hand
  * `gesture01` → Closed Hand
  * `gesture02` → Lateral Pinch
  * `gesture03` → Signalling Sign
  * `gesture04` → Rock Sign
* Raw and processed data are **intentionally separated** for reproducibility

## 3. Project Structure

```
synapse-emg/
├── src/
│   ├── preprocess.py             # Signal normalization & feature extraction
│   ├── dataset.py                # Dataset utilities
│   ├── build_features.py         # Full preprocessing of all CSV files
│   ├── train.py                  # Model training
│   ├── inference.py              # Gesture prediction on new EMG data
│   └── evaluate.py               # Confusion matrix & per-class evaluation
│
├── models/
│   ├── rf_model.pkl              # Trained Random Forest model
│   └── feature_scaler.pkl        # Feature scaler
│
├── data/
├── requirements.txt
└── README.md
```

## 4. Environment Setup

### Python Version

* Python **3.10**

### Install Dependencies

```
pip install -r requirements.txt
```

### `requirements.txt`

```
numpy
pandas
scikit-learn
joblib
matplotlib
```

## 5. Signal Preprocessing & Feature Extraction

Each EMG CSV file undergoes the following preprocessing steps:

### 5.1 Normalization

* Z-score normalization applied **per EMG channel**
* Reduces inter-subject and inter-session variability

### 5.2 Feature Extraction

For each of the 8 EMG channels, the following **time-domain features** are extracted:

* Mean Absolute Value (MAV)
* Root Mean Square (RMS)
* Variance
* Maximum amplitude
* Waveform Length (WL)
* Zero Crossing count (ZC)

This results in:

```
8 channels × 6 features = 48 features per sample
```

## 6. Build Preprocessed Dataset (Run Once)

This step converts **all raw CSV files** into ML-ready feature vectors.

```
python src/build_features.py
```

### Expected Output

```
Saved features shape: (2625, 48)
Saved labels shape: (2625,)
```

The output is saved to:

```
data/processed/
├── X_features.npy
└── y_labels.npy
```

## 7. Model Training

A **Random Forest classifier** is used due to its robustness to noisy EMG features and ease of interpretation.

Feature-level standardization is applied using `StandardScaler`.

```
python src/train.py
```

### Expected Output

```
Dataset shape: (2625, 48)
Validation Accuracy: ~0.78
Validation F1 Score: ~0.78
Model saved to models/rf_model.pkl
Scaler saved to models/feature_scaler.pkl
```

## 8. Evaluation: Confusion Matrix & Per-Class Metrics

To analyze gesture-wise performance, run:

```
python src/evaluate.py
```

This script:

* Computes the **confusion matrix**
* Prints **precision, recall, and F1-score per gesture**
* Displays a confusion matrix plot

### Metrics Used

* Accuracy
* Macro F1-score
* Per-class precision & recall

## 9. Inference (Gesture Prediction)

To predict the gesture for a **new EMG recording**, edit the CSV path in `src/inference.py`:

```
test_csv = "data/Synapse_Dataset/Session1/session1_subject_1/gesture00_trial03.csv"
```

Run:

```
python src/inference.py
```

### Example Output

```
Predicted Gesture: Open Hand
```

### Inference Pipeline

```
Raw CSV
  → normalization
  → feature extraction
  → feature scaling
  → trained model
  → predicted gesture
```

Inference can be performed on:

* Unseen trials
* Unseen sessions
* Unseen subjects

## 10. Evaluation Strategy

* **Train–validation split:** 80% / 20% (stratified)
* **Primary metric:** Macro F1-score
* **Additional analysis:** Confusion matrix and per-class performance
* Qualitative inference tests performed on unseen data to assess generalization

## 11. Key Highlights

* Clean separation of raw and processed data
* Reproducible preprocessing pipeline
* Lightweight, explainable machine learning model
* Robust performance despite EMG noise and subject variability
* Suitable for real-time prosthetic and HCI applications

## 12. Limitations & Future Work

### Limitations

* Overlapping muscle activation patterns between gestures
* High inter-subject variability
* Temporal dynamics not explicitly modeled

### Future Work

* Subject-adaptive models
* Deep learning approaches (CNN / LSTM)
* Frequency-domain and time–frequency features
* Real-time streaming inference

## 13. Quick Reproduction Checklist

Run the following commands **in order**:

```
pip install -r requirements.txt
python src/build_features.py
python src/train.py
python src/evaluate.py
python src/inference.py
```

If all steps run successfully, the pipeline is fully functional.

## 14. Team Members
Mrunali Kamerikar
Riddhima Taose
